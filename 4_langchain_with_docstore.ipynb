{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e095a2f-2b72-4ba8-b832-2ec162291162",
   "metadata": {},
   "source": [
    "# 🦜🔗 LangChain agent with docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a8c85a3-40f9-4ec9-b934-4ad408804bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.0.287)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.28.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: google-search-results in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.4.2)\n",
      "Requirement already satisfied: jq in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.7.4)\n",
      "Collecting pypdf (from -r requirements.txt (line 7))\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/b2/5d/c2671fe6b1e799a4e2d2b4e2d58e13a63691f04bb9006e0d91fb47b9c3c0/pypdf-3.16.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-3.16.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.0.36)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.8.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (8.2.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (1.0.0)\n",
      "Downloading pypdf-3.16.0-py3-none-any.whl (276 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.0/276.0 kB\u001b[0m \u001b[31m866.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-3.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "781f2be3-fa34-48f9-ac51-a6316efb2b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f233aca1-34e3-4b00-873d-1f7dae6324a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"langchain.pdf\")\n",
    "texts = loader.load_and_split()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "db.save_local(\"./vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bce2d53-f548-489b-af2f-6c7e928967cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.load_local(\"./vectorstore\", embeddings)\n",
    "retriever = db.as_retriever()\n",
    "llm = ChatOpenAI(temperature = 0)\n",
    "tool = create_retriever_tool(\n",
    "    retriever, \n",
    "    \"search_langchain\",\n",
    "    \"Searches and returns information about langchain and vectorstores.\"\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87870039-bffc-4420-a2e8-01efc5dbd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38dc38bb-1ec6-4b0f-8881-8b385602822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_langchain` with `vectorstore`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content='Llama-Index/GPT-IndexCaseStudy 25\\nas Wikipedia. LlamaIndex creates a vectorized index from your\\ndocument data, making it highly efficient to query. It then uses\\nthis index to identify the most relevant sections of the document\\nbasedonthequery.\\nLlamaIndex is useful because it provides a central interface to\\nconnectyourLLM’swithexternaldataandoffersdataconnectors\\ntoyourexistingdatasourcesanddataformats(API’s,PDF’s,docs,\\nSQL, etc.). It provides a simple, flexible interface between your\\nexternaldataandLLMs.\\nSome projects that use LlamaIndex include building personal as-\\nsistantswithLlamaIndexandGPT-3.5,usingLlamaIndexfordocu-\\nmentretrieval,andcombininganswersacrossdocuments.', metadata={'source': 'langchain.pdf', 'page': 29}), Document(page_content='UsingLLMsToOrganizeInformationinOurGoogleDrives 52\\n14 , the Council of Europe include all forms of physical exe\\n15 rcise, including those completed just for fun.\\nGoogle Drive Example Wrap Up\\nIf you already use Google Drive to store your working notes\\nand other documents, then you might want to expand the simple\\nexample in this chapter to build your own query system for your\\ndocuments.InadditiontoGoogleDrive,IalsouseMicrosoftOffice\\n365andOneDriveinmyworkandpersonalprojects.\\nI haven’t written my own connectors yet for OneDrive but this is\\nonmypersonalto-dolistusingtheMicrosoftlibrary https://github.\\ncom/OneDrive/onedrive-sdk-python .', metadata={'source': 'langchain.pdf', 'page': 56}), Document(page_content='Using LLMs To Organize\\nInformation in Our\\nGoogle Drives\\nMy digital life consists of writing, working as an AI practitioner,\\nandlearningactivitiesthatIjustifywithmyself-imageofa“gentle-\\nmanscientist.”CloudstoragelikeGitHub,GoogleDrive,Microsoft\\nOneDrive,andiCloudarecentraltomyactivities.\\nAbouttenyearsagoIspenttwomonthsofmytimewritingasystem\\nin Clojure that was planned to be my own custom and personal\\nDropBox,augmentedwithvariousNLPtoolsandaFireFoxplugin\\ntosendwebclippingsdirectlytomypersonalsystem.Tobehonest,\\nI stopped using my own project after a few months because the\\ntimeittooktoorganizemyinformationwasagreateropportunity\\ncostthanthevalueIreceived.\\nIn this chapter I am going to walk you through parts of a new\\nsystem that I am developing for my own personal use to help\\nme organize my material on Google Drive (and eventually other\\ncloud services). Don’t be surprised if the completed project is an\\nadditionalexampleinafutureeditionofthisbook!\\nWiththeGooglesetupdirectionslistedbelow,youwillgetapop-up\\nweb browsing window with a warning like (this shows my Gmail\\naddress, you should see your own Gmail address here assuming\\nthat you have recently logged into Gmail using your default web\\nbrowser):', metadata={'source': 'langchain.pdf', 'page': 49}), Document(page_content='ExamplesUsingHuggingFaceOpenSourceModels 69\\nUsingaastandard ColabGPU,thequery/prediction timeismuch\\nfaster.Hereisa linktomyColabnotebook ⁴ifyouwouldpreferto\\nrunthisexampleonColabinsteadofonyourlaptop.\\n⁴https://colab.research.google.com/drive/1Ecg-0iid3AD05zM4HgPXTVHcgkGxyi3q?usp=\\nsharing', metadata={'source': 'langchain.pdf', 'page': 73})]\u001b[0m\u001b[32;1m\u001b[1;3mTo use langchain with a vectorstore, you can follow these steps:\n",
      "\n",
      "1. Install and set up the langchain library.\n",
      "2. Create or obtain a vectorstore that contains the data you want to work with.\n",
      "3. Use langchain to interact with the vectorstore and perform various operations such as querying, retrieving, and manipulating the data.\n",
      "\n",
      "Langchain provides a central interface to connect your language models (LLMs) with external data sources and offers data connectors to your existing data sources and formats, such as APIs, PDFs, documents, SQL, etc. It simplifies the process of integrating and working with data in your LLMs.\n",
      "\n",
      "For more specific instructions and examples, you can refer to the documentation or examples provided by langchain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"How do i use langchain with a vectorstore?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d625e1-0758-49a4-9999-88c53f1500e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
